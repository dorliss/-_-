{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7511cb73-56b8-4846-84ef-119be1af64c9",
      "metadata": {
        "id": "7511cb73-56b8-4846-84ef-119be1af64c9"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d03437b0-71af-474d-afcc-943a67f1dda9",
      "metadata": {
        "id": "d03437b0-71af-474d-afcc-943a67f1dda9"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "# Описание: Импортирует модуль json, который позволяет работать с данными в формате JSON (JavaScript Object Notation).\n",
        "# JSON широко используется для обмена данными между клиентом и сервером, а также для хранения структуры данных.\n",
        "# Зачем: Этот модуль может понадобиться для загрузки или сохранения данных в формате JSON,\n",
        "# особенно если данные используются в дальнейшем анализе или обучении моделей.\n",
        "\n",
        "import numpy as np\n",
        "# Описание: Импортирует библиотеку NumPy, которая предоставляет поддержку работы с многомерными массивами и матрицами,\n",
        "#а также набор математических функций для операций над ними.\n",
        "# Зачем: NumPy часто используется для численных вычислений и обработки данных,\n",
        "# что важно при предварительной обработке данных для машинного обучения.\n",
        "\n",
        "import tensorflow as tf\n",
        "# Описание: Импортирует библиотеку TensorFlow, популярный инструмент для разработки и обучения моделей машинного и глубокого обучения.\n",
        "# Зачем: TensorFlow предоставляет инструменты для создания нейронных сетей, работы с данными и тренировки моделей.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# Описание: Импортирует модуль pyplot из библиотеки Matplotlib, который используется для визуализации данных.\n",
        "# Зачем: Визуализация важна для анализа результатов моделей, понимания их поведения и демонстрации результатов.\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "# Описание: Импортирует LabelEncoder из библиотеки Scikit-learn, который используется для преобразования категориальных данных в числовые значения.\n",
        "# Зачем: Этот процесс необходим, когда алгоритмы машинного обучения требуют входные данные в числовом формате,\n",
        "#а исходные данные представлены категориями (например, строки или классы).\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "# Описание: Импортирует класс Tokenizer из модуль keras.preprocessing.text библиотеки TensorFlow.\n",
        "# Зачем: Tokenizer используется для преобразования текстовых данных в числовые последовательности.\n",
        "# Это необходимо для обработки текстов в задачах, связанных с обработкой естественного языка (NLP).\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "# Описание: Импортирует функцию pad_sequences из модуля keras.preprocessing.sequence библиотеки TensorFlow.\n",
        "# Зачем: Эта функция используется для заполнения (паддинга) последовательностей чисел до одинаковой длины.\n",
        "# Это важно, поскольку модели нейронных сетей ожидают фиксированный размер входных данных.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HZyK8_nhH7A4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "HZyK8_nhH7A4",
        "outputId": "59750bf7-ff25-4970-f076-1d02592b7bfc"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "mount failed",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         )\n\u001b[0;32m--> 277\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: mount failed"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95f53234-e815-45e8-a4a0-558a0ac06cd4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95f53234-e815-45e8-a4a0-558a0ac06cd4",
        "outputId": "14472d12-6964-46a0-dfe8-2c63be93872e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Данные загружены успешно!\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# Путь к вашим файлам на Google Диске\n",
        "train_scenes_path = '/content/drive/My Drive/CLEVR/scenes/CLEVR_train_scenes.json'\n",
        "train_questions_path = '/content/drive/My Drive/CLEVR/questions/CLEVR_train_questions.json'\n",
        "val_scenes_path = '/content/drive/My Drive/CLEVR/scenes/CLEVR_val_scenes.json'\n",
        "val_questions_path = '/content/drive/My Drive/CLEVR/questions/CLEVR_val_questions.json'\n",
        "\n",
        "# Загрузка JSON-файлов\n",
        "with open(train_scenes_path, 'r') as f:\n",
        "    train_scenes = json.load(f)\n",
        "\n",
        "with open(train_questions_path, 'r') as f:\n",
        "    train_questions = json.load(f)\n",
        "\n",
        "with open(val_scenes_path, 'r') as f:\n",
        "    val_scenes = json.load(f)\n",
        "\n",
        "with open(val_questions_path, 'r') as f:\n",
        "    val_questions = json.load(f)\n",
        "\n",
        "# Теперь данные загружены в переменные\n",
        "print(\"Данные загружены успешно!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be47c27f-4724-468a-b6f6-489d27733d74",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "be47c27f-4724-468a-b6f6-489d27733d74",
        "outputId": "cf3b2404-45ae-4527-edfb-752aaa03dec5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_questions' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-9b766f2abc33>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#Как это работает:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#Используя списковое включение (list comprehension), код проходит по всем вопросам в обоих наборах данных и извлекает текст вопроса (q['question']).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mall_questions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'question'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_questions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'questions'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mval_questions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'questions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Combined questions for tokenization\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_questions' is not defined"
          ]
        }
      ],
      "source": [
        "### 1. Объединение вопросов из обучающего и валидационного наборов данных\n",
        "#Что происходит:\n",
        "#Здесь создается список all_questions, который содержит все вопросы из обучающего (train_questions) и валидационного (val_questions) наборов данных.\n",
        "\n",
        "#Как это работает:\n",
        "#Используя списковое включение (list comprehension), код проходит по всем вопросам в обоих наборах данных и извлекает текст вопроса (q['question']).\n",
        "all_questions = [q['question'] for q in train_questions['questions'] + val_questions['questions']]\n",
        "print(\"Combined questions for tokenization\")\n",
        "\n",
        "### 2. Инициализация токенизатора\n",
        "#Что происходит:\n",
        "#Создается экземпляр Tokenizer из библиотеки Keras.\n",
        "#Токенизатор будет использоваться для преобразования текста вопросов в последовательности целых чисел, где каждое слово будет сопоставлено\n",
        "#с уникальным целым числом\n",
        "\n",
        "#Параметры:\n",
        "#oov_token='<OOV>': Этот параметр задает токен, который будет использоваться для \"неизвестных\" (out-of-vocabulary, OOV) слов,\n",
        "#т.е. слов, которых нет в словаре токенизатора.\n",
        "question_tokenizer = Tokenizer(oov_token='<OOV>')\n",
        "\n",
        "### 3. Обучение токенизатора на текстах вопросов\n",
        "#Что происходит:\n",
        "#Метод fit_on_texts обучает токенизатор на текстах из списка all_questions.\n",
        "#Это позволит нам позже преобразовать вопросы в последовательности целых чисел, готовых к подаче в нейронную сеть\n",
        "\n",
        "#Что делает:\n",
        "#Он создает словарь, где каждому уникальному слову присваивается уникальный индекс (номер). Слова, встречающиеся чаще, будут получать более низкие индексы.\n",
        "question_tokenizer.fit_on_texts(all_questions)\n",
        "print(\"Tokenizer initialized\")\n",
        "\n",
        "### 4. Преобразование обучающих вопросов в последовательности чисел\n",
        "#Что происходит:\n",
        "#Вопросы из обучающего набора преобразуются в последовательности чисел с помощью метода texts_to_sequences.\n",
        "#Это позволяет нейронной сети обрабатывать текстовые данные в числовом формате\n",
        "#Результат:\n",
        "#X_train_questions_seq будет представлять собой список списков, где каждый внутренний список соответствует последовательности токенов для одного текста вопроса.\n",
        "X_train_questions_seq = question_tokenizer.texts_to_sequences([q['question'] for q in train_questions['questions']])\n",
        "\n",
        "### 5. Преобразование валидационных вопросов в последовательности чисел\n",
        "#Что происходит:\n",
        "#Bалидационные вопросы преобразуются в последовательности чисел. Это предусмотрено для оценки производительности модели на отдельных валидационных данных.\n",
        "#Результат:\n",
        "#X_val_questions_seq будет содержать такие же последовательности токенов для вопросов из валидационного набора.\n",
        "X_val_questions_seq = question_tokenizer.texts_to_sequences([q['question'] for q in val_questions['questions']])\n",
        "print(\"Train & Val seq converted\")\n",
        "\n",
        "### 6. Определение максимальной длины вопроса\n",
        "#Что происходит:\n",
        "#Код вычисляет максимальную длину среди всех последовательностей вопросов (как из обучающего, так и из валидационного наборов).\n",
        "#Это значение будет использоваться для выравнивания (padding) последовательностей до одинаковой длины, чтобы обеспечить совместимый ввод для модели.\n",
        "#Как это делает:\n",
        "#Используя генераторное выражение, он проходит по спискам и находит длину каждой последовательности, затем берёт максимальное значение.\n",
        "max_question_length = max(len(seq) for seq in X_train_questions_seq + X_val_questions_seq)\n",
        "\n",
        "### 7. Выравнивание обучающих вопросов\n",
        "#Что происходит:\n",
        "#Метод pad_sequences используется для выравнивания последовательностей X_train_questions_seq до заданной максимальной длины max_question_length.\n",
        "#Модели, такие как RNN или LSTM, требуют, чтобы все входные данные имели одинаковую длину\n",
        "#Как работает:\n",
        "#Если последовательность короче максимальной длины, она будет дополнена (паддирована) специальными значениями (по умолчанию нулем)\n",
        "#в конце (параметр padding='post').\n",
        "X_train_questions_padded = pad_sequences(X_train_questions_seq, maxlen=max_question_length, padding='post')\n",
        "\n",
        "### 8. Выравнивание валидационных вопросов\n",
        "#Что происходит:\n",
        "#Здесь производится выравнивание последовательностей для валидационных вопросов, используя максимальную длину.\n",
        "#Результат:\n",
        "#X_val_questions_padded будет содержать паддированные последовательности для вопросов валидационного набора, готовые для подачи в модель.\n",
        "X_val_questions_padded = pad_sequences(X_val_questions_seq, maxlen=max_question_length, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "250cac3b-4418-4f17-9414-7e70ad7c36ce",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "250cac3b-4418-4f17-9414-7e70ad7c36ce",
        "outputId": "a2bcc04f-42c5-4294-a660-9dbb4ee1f8c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train & Val data extracted\n"
          ]
        }
      ],
      "source": [
        "### Функция extract_features\n",
        "# Эта функция извлекает атрибуты объектов, находящихся в сцене, и собирает их в один список.\n",
        "# Параметр: scene — это словарь, представляющий одну сцену, содержащий список объектов.\n",
        "def extract_features(scene):\n",
        "    features = [] # Создаем пустой список для хранения извлеченных атрибутов.\n",
        "    for obj in scene['objects']: # Перебираем все объекты в сцене.\n",
        "        attributes = [obj['size'], obj['color'], obj['material'], obj['shape']]\n",
        "        # Извлекаем атрибуты (размер, цвет, материал, форма) для каждого объекта и сохраняем их в списке attributes.\n",
        "        features.extend(attributes) # Добавляем извлеченные атрибуты в общий список features\n",
        "    return features # Возвращаем собранные атрибуты объектов как один плоский список\n",
        "\n",
        "### Функция prep_dataset\n",
        "# Эта функция подготавливает обучающий набор данных (входные и выходные данные) на основе сцен и вопросов.\n",
        "def prep_dataset(scenes, questions):\n",
        "    X = [] # Создаем пустые списки для хранения входных данных и ответов.\n",
        "    y = [] # Создаем пустые списки для хранения входных данных и ответов.\n",
        "    s_dict = {scene['image_index']: scene for scene in scenes['scenes']}\n",
        "    # Создаем словарь (s_dict) для быстрого доступа к сценам по их image_index.\n",
        "    # Это позволит быстро находить сцену, соответствующую вопросу, без необходимости перебора всех сцен.\n",
        "    for question in questions['questions']: # Перебираем все вопросы\n",
        "        image_index = question['image_index'] # Получаем индекс изображения, которому соответствует вопрос\n",
        "        if image_index in s_dict: # Проверяем, существует ли сцена с таким image_index в нашем словаре.\n",
        "            scene = s_dict[image_index] # Находим соответствующую сцену\n",
        "            features = extract_features(scene) # Извлекаем атрибуты объектов сцены с помощью функции extract_features\n",
        "            X.append(features) # Добавляем извлеченные файлы в список X (входные данные).\n",
        "            y.append(question['answer']) # Добавляем правильный ответ на вопрос в список y (выходные данные).\n",
        "    return X, y #Возвращаем совместимые наборы данных X и y\n",
        "\n",
        "### Извлечение данных для обучения и валидации\n",
        "# - print(\"Train & Val data extracted\"): Выводит сообщение о завершении извлечения данных.\n",
        "X_train_scenes_raw, y_train_raw = prep_dataset(train_scenes, train_questions)\n",
        "# Мы вызываем функцию prep_dataset для извлечения данных из тренировочного и валидационного наборов.\n",
        "X_val_scenes_raw, y_val_raw = prep_dataset(val_scenes, val_questions)\n",
        "# Результаты сохраняются в переменных X_train_scenes_raw, y_train_raw для обучения и X_val_scenes_raw, y_val_raw для валидации.\n",
        "print(\"Train & Val data extracted\") # Выводит сообщение о завершении извлечения данных.\n",
        "\n",
        "### Код для кодирования и дополнения последовательностей\n",
        "# Создает один список, в который объединяются все атрибуты из обоих наборов данных X_train_scenes_raw и X_val_scenes_raw.\n",
        "# Этот список будет использоваться для кодирования.\n",
        "\n",
        "all_features = [item for sublist in X_train_scenes_raw + X_val_scenes_raw for item in sublist]\n",
        "# Создает один список, в который объединяются все атрибуты из обоих наборов данных\n",
        "scene_encoder = LabelEncoder() # Создаем экземпляр LabelEncoder из библиотеки sklearn,\n",
        "#который будет использоваться для кодирования категориальных данных в числовые индексы.\n",
        "scene_encoder.fit(all_features) # Обучаем кодировщик на всех извлеченных атрибутах\n",
        "# (т.е. создаем словарь, где каждому уникальному атрибуту присваивается числовой индекс).\n",
        "\n",
        "### Кодирование и дополнение последовательностей\n",
        "X_train_scenes_encoded = [scene_encoder.transform(features) for features in X_train_scenes_raw]\n",
        "# Применяем кодер к каждым из features в тренировочных данных, преобразовывая их в числовые индексы.\n",
        "X_val_scenes_encoded = [scene_encoder.transform(features) for features in X_val_scenes_raw]\n",
        "# То же самое для валидационных данных\n",
        "\n",
        "### Дополнение последовательностей\n",
        "max_scene_length = max(len(seq) for seq in X_train_scenes_encoded + X_val_scenes_encoded)\n",
        "# Находим максимальную длину среди закодированных последовательностей, чтобы знать,\n",
        "# до какого размера нужно дополнять (или обрезать) остальные последовательности\n",
        "X_train_scenes_padded = pad_sequences(X_train_scenes_encoded, maxlen=max_scene_length, padding='post')\n",
        "X_val_scenes_padded = pad_sequences(X_val_scenes_encoded, maxlen=max_scene_length, padding='post')\n",
        "# Используя функцию pad_sequences из Keras, дополняем последовательности до одинаковой длины (max_scene_length)\n",
        "# padding='post' значит, что нули будут добавляться в конец последовательностей, если они короче заданной длины\n",
        "# Результат этих операций сохраняется в X_train_scenes_padded и X_val_scenes_padded,\n",
        "# что позволяет входным данным иметь одинаковую длину для подачи в модель."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd110141-5f45-4132-8509-eb140f6b4457",
      "metadata": {
        "id": "fd110141-5f45-4132-8509-eb140f6b4457",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "d093aaea-bd1d-4cc3-de53-30fdcdc41efa"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'y_train_raw' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-bdc2d773a6df>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# all_answers: Здесь мы объединяем два списка (y_train_raw и y_val_raw) в один, чтобы кодировать все уникальные ответы в одном процессе.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Это необходимо для того, чтобы убедиться, что все ответные метки из тренировочного и валидационного наборов будут известны кодировщику.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mall_answers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train_raw\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my_val_raw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m### Создание экземпляра LabelEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y_train_raw' is not defined"
          ]
        }
      ],
      "source": [
        "### Код для кодирования ответов\n",
        "# Цель:\n",
        "# Создать единый список всех ответов из тренировочного и валидационного наборов.\n",
        "\n",
        "# y_train_raw: Это изначальный список ответов для тренировочного набора, полученный из функции prep_dataset.\n",
        "# y_val_raw: Это изначальный список ответов для валидационного набора.\n",
        "# all_answers: Здесь мы объединяем два списка (y_train_raw и y_val_raw) в один, чтобы кодировать все уникальные ответы в одном процессе.\n",
        "# Это необходимо для того, чтобы убедиться, что все ответные метки из тренировочного и валидационного наборов будут известны кодировщику.\n",
        "all_answers = y_train_raw + y_val_raw\n",
        "\n",
        "### Создание экземпляра LabelEncoder\n",
        "# Цель:\n",
        "# Создать экземпляр класса LabelEncoder из библиотеки sklearn, который будет использоваться для преобразования меток в числовые значения.\n",
        "# LabelEncoder: Этот класс используется для кодирования категориальных переменных, где каждое уникальное значение (в данном случае ответ) будет преобразовано в уникальный целочисленный индекс.\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "### \"Обучение\" кодировщика\n",
        "# Цель:\n",
        "# \"Обучить\" кодировщик на данных о всех ответах.\n",
        "# fit(): Метод fit() берет уникальные значения из all_answers и создает соответствие между уникальными ответами и их числовыми индексами.\n",
        "# Например, если у вас есть ответы [\"yes\", \"no\", \"maybe\"], они будут кодированы как [0, 1, 2] соответственно.\n",
        "# Этот шаг необходим, чтобы LabelEncoder знал, какие метки встречаются в данных и как их кодировать.\n",
        "label_encoder.fit(all_answers)\n",
        "\n",
        "### Кодирование ответов для тренировочного набора\n",
        "# Цель:\n",
        "# Преобразовать оригинальные ответы тренировочного набора в числовые индексы.\n",
        "# transform(): Метод transform() принимает список оригинальных меток (y_train_raw)\n",
        "# и возвращает новый массив, где каждый ответ заменен соответствующим числовым значением, найденным на этапе fit().\n",
        "# Таким образом, вместо текста вы получите массив чисел, которые могут быть использованы в машинном обучении.\n",
        "y_train_encoded = label_encoder.transform(y_train_raw)\n",
        "\n",
        "### Кодирование ответов для валидационного набора\n",
        "# Цель: То же, что и на предыдущем шаге, но для валидационного набора.\n",
        "# ransform(): Аналогично, превращает оригинальные ответы y_val_raw в числовые индексы.\n",
        "# Здесь важно, что метод использует то же соответствие, которое было создано на этапе fit(),\n",
        "# чтобы обеспечить согласованность между тренировочными и валидационными данными.\n",
        "y_val_encoded = label_encoder.transform(y_val_raw)\n",
        "print(y_val_encoded)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fcc3df30-cef7-4cb3-b9ac-a2bcfc5d6180",
      "metadata": {
        "id": "fcc3df30-cef7-4cb3-b9ac-a2bcfc5d6180"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "775a6f41-a402-40c2-a883-c6169ae7683e",
      "metadata": {
        "id": "775a6f41-a402-40c2-a883-c6169ae7683e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "450b8fca-b05e-4cc7-a2be-d55bb6ba3772"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'tf' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-c4dd6249ba11>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### 1. Определение входного слоя\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mq_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_question_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'question_input'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# tf.keras.layers.Input: Это функция, которая создает входной слой для модели Keras. Он определяет форму входных данных.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# shape=(max_question_length,): Указывает, что входные данные – это последовательности фиксированной длины,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# где max_question_length – это максимальная длина вопроса (в символах или словах). Это помогает модели знать, какую форму имеют входные данные.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
          ]
        }
      ],
      "source": [
        "### 1. Определение входного слоя\n",
        "q_input = tf.keras.layers.Input(shape=(max_question_length,), name='question_input')\n",
        "# tf.keras.layers.Input: Это функция, которая создает входной слой для модели Keras. Он определяет форму входных данных.\n",
        "# shape=(max_question_length,): Указывает, что входные данные – это последовательности фиксированной длины,\n",
        "# где max_question_length – это максимальная длина вопроса (в символах или словах). Это помогает модели знать, какую форму имеют входные данные.\n",
        "# name='question_input': Указывает имя для входного слоя, что может быть полезно при отладке и визуализации структуры модели.\n",
        "\n",
        "### 2. Встраивание слов (Embedding Layer)\n",
        "# Эмбеддинг (или векторное представление) — это способ представления дискретных объектов (таких как слова, символы или даже целые предложения)\n",
        "# в виде непрерывных векторов в многомерном пространстве.\n",
        "# Этот метод широко используется в задачах обработки естественного языка (NLP) и в других областях машинного обучения для преобразования категориальных данных\n",
        "# в числовую форму, которую модели могут эффективно обрабатывать.\n",
        "q_embedding = tf.keras.layers.Embedding(\n",
        "    input_dim=len(question_tokenizer.word_index) + 1,  # +1 for OOV (out of voc)\n",
        "    output_dim=128, # dims\n",
        "    mask_zero=True # mask\n",
        ")(q_input)\n",
        "# tf.keras.layers.Embedding: Это слой встраивания, который преобразует целочисленные представления слов в плотные векторы фиксированной длины.\n",
        "# Этот слой обучается в процессе тренировки модели.\n",
        "# input_dim=len(question_tokenizer.word_index) + 1: Значение input_dim указывает на размер словаря. question_tokenizer.word_index содержит индексы всех слов,\n",
        "# которые были токенизированы, и если максимальный индекс – это количество уникальных слов, то мы добавляем 1 для учета символа \"разнообразия\" (OOV) для слов,\n",
        "# не включённых в словарь.\n",
        "# output_dim=128: Это размер векторного пространства, в котором слова будут представлены.\n",
        "# Чем выше это значение, тем более подробно модель может быть обучена, но также и большее количество параметров и риск переобучения.\n",
        "# mask_zero=True: Эта функция сообщает модели игнорировать вектор, представляющий \"ноль\",\n",
        "# что полезно для обработки последовательностей переменной длины.\n",
        "#Обычно \"ноль\" используется для заполнения последовательностей, которые короче максимальной длины (padding).\n",
        "\n",
        "### 3. Применение LSTM\n",
        "question_lstm = tf.keras.layers.LSTM(64)(q_embedding)\n",
        "# Создает и применяет слой LSTM (Long Short-Term Memory) к векторному представлению входящих данных, которые были получены после их эмбеддинга.\n",
        "# экземпляр LSTM слоя с 64 единицами (или нейронами). Число 64 указывает на количество «скрытых» состояний в этом слое,\n",
        "# что в свою очередь определяет размер выходного вектора, который будет передан на следующий слой сети.\n",
        "# Это число можно выбрать в зависимости от сложности задачи и объема данных.\n",
        "\n",
        "# ### Подробное описание\n",
        "\n",
        "# 1. Что такое LSTM?\n",
        "# LSTM — это тип рекуррентной нейронной сети (RNN), которая может запоминать информацию на длительные промежутки времени.\n",
        "# Это делает LSTM особенно полезными для обработки последовательных данных, таких как текст или временные ряды. В отличие от обычных RNN,\n",
        "# LSTM решает проблему исчезающего градиента, что позволяет ему эффективно запоминать и извлекать информацию из последовательностей.\n",
        "\n",
        "# 3. Применение LSTM к входным данным:\n",
        "#  (q_embedding) — это входные данные, которые мы передаем в LSTM слой. На этом этапе предполагается, что данные уже прошли через слой эмбеддинга (q_embedding),\n",
        "#  что означает:\n",
        "#   Каждое слово в предложении теперь представлено вектором фиксированной длины (в данном случае 128, как указано в output_dim слоя Embedding).\n",
        "#   Эмбеддинг позволяет захватывать семантические отношения между словами, что важно для анализа текста.\n",
        "\n",
        "# 4. Что в итоге?\n",
        "#  Результатом применения LSTM к q_embedding будет выходной вектор, который summarizes (обобщает) информацию о входной последовательности.\n",
        "# Этот вектор будет иметь размерность 64 (число нейронов в LSTM), и его можно использовать в следующих слоях для дальнейшей обработки\n",
        "# (например, для классификации или извлечения признаков).\n",
        "\n",
        "# ### Зачем это нужно?\n",
        "# - Применение LSTM позволяет сети учитывать контекст и порядок слов в предложении.\n",
        "# Это критически важно для понимания смысла текста, так как порядок слов часто влияет на значение.\n",
        "# ЛСТМ может научиться не только на что-то реагировать в текущий момент (например, текущее слово), но и сохранять информацию о предыдущих словах,\n",
        "# что улучшает качество обработки естественного языка.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13034f1b-8717-4aeb-8b02-a3eb238259db",
      "metadata": {
        "id": "13034f1b-8717-4aeb-8b02-a3eb238259db"
      },
      "outputs": [],
      "source": [
        "# scene\n",
        "s_input = tf.keras.layers.Input(shape=(max_scene_length,), name='scene_input')\n",
        "s_embedding = tf.keras.layers.Embedding(\n",
        "    input_dim=len(scene_encoder.classes_),\n",
        "    output_dim=128,\n",
        "    mask_zero=True\n",
        ")(s_input)\n",
        "scene_lstm = tf.keras.layers.LSTM(64)(s_embedding)\n",
        "\n",
        "# все тоже самое, что и в предыдущем, но только работа со сценами"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc227876-864d-4a1d-885f-66e3999706f1",
      "metadata": {
        "id": "cc227876-864d-4a1d-885f-66e3999706f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "c630b133-73ff-48d9-d526-490ea24e17f1"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-5-61983b3c06e8>, line 27)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-61983b3c06e8>\"\u001b[0;36m, line \u001b[0;32m27\u001b[0m\n\u001b[0;31m    Каждая выходная вероятность соответствует вероятности принадлежности к конкретному классу.\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "### 1. Объединение LSTM выхода\n",
        "# Когда объединяются выходы двух LSTM, результатом является один тензор, который содержит информацию как из вопроса, так и из сцены.\n",
        "# Это позволяет модели учитывать контекст обоих компонентов при дальнейшем прогнозировании.\n",
        "# combined: Здесь создается новый тензор, который представляет собой объединение (конкатенацию) выходов двух сетей LSTM — question_lstm\n",
        "#  (выход из LSTM для вопроса) и scene_lstm (выход из LSTM для сцены).\n",
        "#  tf.keras.layers.concatenate: Эта функция принимает список тензоров (в данном случае question_lstm и scene_lstm) и\n",
        "# соединяет их вдоль указанной оси (по умолчанию вдоль второй оси, то есть по размерности признаков).\n",
        "combined = tf.keras.layers.concatenate([question_lstm, scene_lstm])\n",
        "\n",
        "### 2. Полносвязный слой (Dense layer)\n",
        "# fc1: Здесь создается полносвязный слой, который будет обрабатывать объединенные данные от предыдущего шага.\n",
        "# tf.keras.layers.Dense(64, activation='relu'): Этот полносвязный слой имеет 64 нейрона и использует активацию ReLU (Rectified Linear Unit).\n",
        "# Dense: Полносвязный слой, в котором каждый нейрон получает входные данные от всех нейронов предыдущего слоя.\n",
        "# 64: Количество нейронов в этом слое; это означает, что выходом будет вектор длины 64,\n",
        "# который будет содержать сжатую и обработанную информацию из входного тензора.\n",
        "# activation='relu': Активация ReLU помогает добавить нелинейность в модель, что важно для обучения более сложных зависимостей.\n",
        "fc1 = tf.keras.layers.Dense(64, activation='relu')(combined)\n",
        "\n",
        "### 3. Выходной слой\n",
        "# output: Это выходной слой, который создает предсказания на основе данных, полученных из fc1.\n",
        "# len(label_encoder.classes_): Здесь количество нейронов в слое равно количеству классов (или меток),\n",
        "# которые модель должна предсказать. label_encoder.classes_ содержит все возможные метки (например, категории или классы) в задаче классификации.\n",
        "# tf.keras.layers.Dense(len(label_encoder.classes_), activation='softmax'):\n",
        "# В этом полносвязном слое будет столько нейронов, сколько классов (меток) в задаче классификации.\n",
        "# Используется активация 'softmax', чтобы превратить выходы в вероятности, что делает этот слой подходящим для многоклассовой классификации.\n",
        "# softmax: Это функция активации, которая преобразовывает необработанные логиты в вероятности, суммирующиеся до 1.\n",
        "# Каждая выходная вероятность соответствует вероятности принадлежности к конкретному классу.\n",
        "output = tf.keras.layers.Dense(len(label_encoder.classes_), activation='softmax')(fc1)\n",
        "\n",
        "### 4. Определение модели\n",
        "# model: Создается объект модели Keras.\n",
        "# tf.keras.models.Model: Это класс Model из Keras, который принимает два обязательных аргумента: inputs и outputs.\n",
        "# inputs=[q_input, s_input]: Указывает, что модель будет принимать два входа: q_input (вход для вопроса) и s_input (вход для сцены).\n",
        "# outputs=output: Указывает, что выходом модели будет output, который является вероятностным распределением по классам.\n",
        "model = tf.keras.models.Model(inputs=[q_input, s_input], outputs=output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f4b0524-8515-46e5-9c3e-49552abe205a",
      "metadata": {
        "id": "7f4b0524-8515-46e5-9c3e-49552abe205a"
      },
      "outputs": [],
      "source": [
        "# Результатом этой строки кода является подготовка модели Keras к обучению.\n",
        "# Она знает, как оптимизировать свои параметры (веса),\n",
        "# как оценивать качество предсказаний и какие метрики использовать для отслеживания успеха в повышении точности.\n",
        "# После компиляции модели можно приступать к обучению на данных\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# model.compile: Это метод, который связывает архитектуру вашей модели с выбранным алгоритмом оптимизации,\n",
        "# функцией потерь и метриками, которые будут использованы во время обучения. Компиляция модели — это обязательный шаг перед началом процесса обучения.\n",
        "\n",
        "# optimizer='adam': Здесь указывается алгоритм оптимизации, который будет использоваться для обновления весов модели во время обучения.\n",
        "# Adam: Это один из наиболее популярных и часто используемых оптимизаторов в глубоких нейронных сетях.\n",
        "# Он сочетает в себе преимущества двух других методов: AdaGrad и RMSProp.\n",
        "# Adam адаптирует скорость обучения для каждого параметра (веса) на основе оценок первого и второго момента градиента\n",
        "# (среднее значение и среднее квадратичное значение), что делает его эффективным на больших данных и в таких задачах, как обучение глубоких нейронных сетей.\n",
        "# Этот оптимизатор автоматически корректирует скорость обучения на основе прошлых градиентов, что помогает в более стабильной и быстрой сходимости.\n",
        "\n",
        "# loss='sparse_categorical_crossentropy': Указывается функция потерь, используемая для оценки качества модели от предсказаний до истинных значений.\n",
        "# sparse_categorical_crossentropy: Эта функция потерь предназначена для многоклассовой классификации, где ваши метки классов представлены как целые числа\n",
        "# (например, 0, 1, 2 и т. д.), а не как one-hot закодированные векторы.\n",
        "# Это полезно, когда у вас много классов, так как она экономит память и вычислительные ресурсы,\n",
        "# избегая необходимости создавать дополнительные векторы для каждого класса.\n",
        "# Она рассчитывает степень \"дискриминации\" между предсказаниями и реальными классами и использует эту информацию для обновления весов в процессе обучения.\n",
        "\n",
        "# metrics=['accuracy']: Здесь указывается список метрик, которые нужно отслеживать для оценки производительности модели во время обучения и валидации.\n",
        "# accuracy: Это метрика, измеряющая долю правильных предсказаний.\n",
        "# В контексте многоклассовой классификации это вычисляется как количество правильно предсказанных классов, деленное на общее количество примеров.\n",
        "# Эта метрика позволяет легко понять, насколько хорошо модель классифицирует входные данные.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90b6ec57-5d95-404e-a7cf-136420bc672c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "90b6ec57-5d95-404e-a7cf-136420bc672c",
        "outputId": "b1ffe874-2e18-41d7-d355-cb6333e52b5a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ question_input            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ scene_input (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │         \u001b[38;5;34m10,496\u001b[0m │ question_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ not_equal (\u001b[38;5;33mNotEqual\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ question_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │          \u001b[38;5;34m1,920\u001b[0m │ scene_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ not_equal_1 (\u001b[38;5;33mNotEqual\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ scene_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m49,408\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                           │                        │                │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m49,408\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│                           │                        │                │ not_equal_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],            │\n",
              "│                           │                        │                │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m8,256\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m)             │          \u001b[38;5;34m1,820\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ question_input            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ scene_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">10,496</span> │ question_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ not_equal (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ question_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,920</span> │ scene_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ not_equal_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ scene_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                           │                        │                │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│                           │                        │                │ not_equal_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],            │\n",
              "│                           │                        │                │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,820</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m121,308\u001b[0m (473.86 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">121,308</span> (473.86 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m121,308\u001b[0m (473.86 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">121,308</span> (473.86 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Метод model.summary() в Keras предоставляет сводную информацию о модели, которую вы создали.\n",
        "# Это полезный инструмент для понимания структуры вашей нейронной сети, её архитектуры и параметров.\n",
        "\n",
        "# Вывод структурной информации о модели: Когда вы вызываете model.summary(), Keras выводит текстовую сводку, которая включает в себя следующие элементы:\n",
        "# Список слоев: Отображает каждый слой модели в том порядке, в котором они были добавлены.\n",
        "# Для каждого слоя вы увидите его тип (например, Dense, LSTM, Dropout, Activation, и т. д.) и его название (если применимо).\n",
        "# Выходные данные каждого слоя: Для каждого слоя показывается форма тензора, который он генерирует (например, (None, 64) для слоя с 64 нейронами).\n",
        "# Здесь None часто используется для представления переменной размерности (например, размер батча).\n",
        "# Количество параметров: Для каждого слоя указано количество обучаемых параметров (весов и смещений) и общее количество параметров в модели.\n",
        "# Обратите внимание, что для некоторых типов слоев (например, Dropout) количество параметров будет равно нулю, так как в этих слоях нет обучаемых параметров.\n",
        "# Общая информация о модели: После сводного списка слоев вы также увидите общая информация о модели, включая общее количество параметров,\n",
        "# общее количество обучаемых и необучаемых параметров.\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49b6f8ff-4fc1-413e-842a-25103818f2c5",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "49b6f8ff-4fc1-413e-842a-25103818f2c5",
        "outputId": "5d4a6eb9-5cc3-4d97-b1ea-5fed5a9c08e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m21875/21875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1948s\u001b[0m 89ms/step - accuracy: 0.4572 - loss: 1.0619 - val_accuracy: 0.5257 - val_loss: 0.8912\n",
            "Epoch 2/10\n"
          ]
        }
      ],
      "source": [
        "# Строка кода запускает процесс обучения модели, используя подготовленные входные данные и метки,\n",
        "# и в процессе обучения отслеживает производительность модели на валидационном наборе.\n",
        "# Это важный этап в создании модели машинного обучения, позволяющий модель эффективно адаптироваться к обучающим данным и обобщать производительность на новых,\n",
        "# незнакомых данных. В результате, объект history будет содержать информацию о метриках каждой эпохи,\n",
        "# что может быть полезно для дальнейшего анализа и визуализации результатов обучения.\n",
        "\n",
        "history = model.fit(\n",
        "    {'question_input': X_train_questions_padded, 'scene_input': X_train_scenes_padded},\n",
        "    y_train_encoded,\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    validation_data=(\n",
        "        {'question_input': X_val_questions_padded, 'scene_input': X_val_scenes_padded},\n",
        "        y_val_encoded\n",
        "    )\n",
        ")\n",
        "\n",
        "### 1. history = model.fit(...)\n",
        "\n",
        "# model.fit(...): Это метод, который запускает процесс обучения модели на предоставленных данных.\n",
        "# Он обучает модель, основываясь на входных данных и соответствующих метках, и возвращает объект history,\n",
        "# содержащий информацию об истории обучения (например, значения функции потерь и метрик после каждой эпохи).\n",
        "\n",
        "### 2. {'question_input': X_train_questions_padded, 'scene_input': X_train_scenes_padded}\n",
        "\n",
        "# входные данные: Этот параметр указывает, какие данные используются для обучения модели.\n",
        "# 'question_input': Имя первого входа модели, соответствующее данным вопросов, подготовленным с помощью предобработки (например, дополнение до фиксированной длины).\n",
        "# X_train_questions_padded: Это массив, содержащий подготовленные данные для обучения, которые представляют собой вопросы, возможно, в виде последовательностей индексов (например, токенов).\n",
        "# 'scene_input': Имя второго входа модели, соответствующее данным сцен.\n",
        "# X_train_scenes_padded: Это массив, содержащий подготовленные данные для обучения, представляющие собой сцены, также в виде последовательностей индексов.\n",
        "\n",
        "### 3. y_train_encoded\n",
        "\n",
        "#  y_train_encoded: Это метки классов для обучающих данных, закодированные в формате,\n",
        "# подходящем для выбранной функции потерь (в данном случае — для sparse_categorical_crossentropy).\n",
        "# Эти метки указывают, к какому классу принадлежит каждый пример в обучающем наборе данных.\n",
        "\n",
        "### 4. epochs=10\n",
        "\n",
        "# epochs=10: Это количество итераций (эпох) по всему набору обучающих данных, которые модель будет проходить.\n",
        "# Каждый проход — это одна эпоха, в течение которой модель обновляет свои веса на основе всех обучающих примеров.\n",
        "# 10 эпох — это экспериментальное значение, которое означает, что модель будет обучаться 10 полных раз на всех примерах из обучающей выборки.\n",
        "\n",
        "### 5. batch_size=32\n",
        "\n",
        "# batch_size=32: Это количество примеров, которые будут использоваться для обновления весов модели за один шаг.\n",
        "# В данном случае модель будет обрабатывать 32 примера за раз и затем обновлять свои веса.\n",
        "# Чем меньше размер батча, тем чаще обновляются веса, что может привести к более быстрым изменениям,\n",
        "# но может быть менее стабильным. Размер 32 является довольно распространенным значением.\n",
        "\n",
        "### 6. validation_data=...\n",
        "\n",
        "# validation_data=...: Этот параметр позволяет указать данные для валидации, которые используются для оценки производительности модели в процессе обучения.\n",
        "# {'question_input': X_val_questions_padded, 'scene_input': X_val_scenes_padded}: Входные данные для валидации такие же, как и для обучения, но представляют собой отдельный набор данных.\n",
        "# Эти данные помогают предотвратить переобучение, так как модель будет упоминаться о своей производительности на незадействованных данных.\n",
        "# y_val_encoded: Это метки классов для валидационного набора."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "441e9f93-e5a5-4064-adee-97a3ebcf72b6",
      "metadata": {
        "id": "441e9f93-e5a5-4064-adee-97a3ebcf72b6"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 5))\n",
        "# Создает новое окно графика или фигуры. Параметр figsize задает размеры фигуры в дюймах (ширина = 12 дюймов, высота = 5 дюймов).\n",
        "# Это позволяет контролировать размеры графиков, чтобы они были четкими и удобными для восприятия.\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "# Настраивает подграфик в фигуре, который будет занимать место в комбинации из 1 строки и 2 столбцов, указывая на первый подграфик.\n",
        "# Это создает структуру, в которой можно разместить несколько графиков в одной фигуре.\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='T-Accuracy', marker='o') # Строит график для точности обучения (accuracy) модели.\n",
        "#  history.history['accuracy']: Доступ к списку значений точности, собранных в процессе обучения модели на обучающей выборке (train accuracy).\n",
        "#  label='T-Accuracy': Название линии на графике для легенды, обозначает точность обучения.\n",
        "#  marker='o': Используется для отображения маркеров в виде кружков для каждой точки данных на графике.\n",
        "\n",
        "plt.plot(history.history['val_accuracy'], label='V-Accuracy', marker='o') # Строит график для точности валидации модели.\n",
        "# history.history['val_accuracy']: Доступ к списку значений точности, собранных во время проверки валидационной выборки (validation accuracy).\n",
        "# label='V-Accuracy': Название линии на графике для легенды, обозначает точность валидации.\n",
        "#  marker='o': Используется для отображения маркеров в виде кружков для каждой точки данных на графике.\n",
        "\n",
        "plt.title('Accuracy') # Устанавливает заголовок для первого подграфика, предлагая понять, что именно показывает этот график (точность).\n",
        "plt.xlabel('Epoch') # Устанавливает метку по оси X, которая показывает количество эпох.\n",
        "# Это значение указывает, сколько раз модель была обучена на всех примерах данных.\n",
        "plt.ylabel('Acc') # Устанавливает метку по оси Y, показывающую значение точности (Accuracy).\n",
        "plt.legend() # Добавляет легенду к графику, позволяя различать линии на графике по их меткам (T-Accuracy и V-Accuracy).\n",
        "plt.grid(True) # Включает сетку на графике, что помогает лучше визуализировать данные и ориентироваться на графике.\n",
        "\n",
        "plt.subplot(1, 2, 2) # Настраивает второй подграфик в той же фигуре, указывая на второй подграфик.\n",
        "plt.plot(history.history['loss'], label='T-Loss', marker='o') # Строит график для значения функции потерь на обучении.\n",
        "# history.history['loss']: Доступ к списку значений функции потерь, собранных в процессе обучения модели на обучающей выборке.\n",
        "# label='T-Loss': Название линии на графике для легенды, обозначает значение функции потерь при обучении.\n",
        "#  marker='o': Используется для отображения маркеров в виде кружков для каждой точки данных на графике.\n",
        "\n",
        "plt.plot(history.history['val_loss'], label='V-Loss', marker='o') # Строит график для значения функции потерь на валидации.\n",
        "# history.history['val_loss']: Доступ к списку значений функции потерь, собранных во время проверки валидационной выборки.\n",
        "# label='V-Loss': Название линии на графике для легенды, обозначает значение функции потерь на валидации.\n",
        "#  marker='o': Используется для отображения маркеров в виде кружков для каждой точки данных на графике.\n",
        "\n",
        "plt.title('Loss') # Устанавливает заголовок для второго подграфика, показывая, что на этом графике будет представлено значение функции потерь.\n",
        "plt.xlabel('Epoch') # Устанавливает метку по оси X для второго графика (также показывает количество эпох).\n",
        "plt.ylabel('Loss') # Устанавливает метку по оси Y для второго графика, показывающую значение функции потерь.\n",
        "plt.legend() # Добавляет легенду ко второму графику, позволяя различать линии по их меткам (T-Loss и V-Loss).\n",
        "plt.grid(True) # Включает сетку на втором графике для лучшего восприятия данных.\n",
        "\n",
        "plt.tight_layout() #Автоматически подстраивает параметры подграфиков и фигуры для улучшения компоновки.\n",
        "# Это помогает избежать наложения графиков и делает визуализацию более чистой.\n",
        "plt.show() # Отображает все построенные графики и влияет на то, что мы видим в окне. Как только эта команда выполнена, графики станут видимыми."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fed8012-1e20-4ee2-b787-90534aa2a17c",
      "metadata": {
        "id": "4fed8012-1e20-4ee2-b787-90534aa2a17c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "a41b62a5-78b1-4d75-a3fd-18ee244d445a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'np' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e12df5562358>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#Это полезно для быстрой проверки работы модели и визуализации результатов без необходимости обрабатывать весь валидационный набор.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#Выбор случайных вопросов также помогает избежать предвзятости, связанной с последовательным выбором.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mxindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_questions_padded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m#np.random.choice: Эта функция используется для случайного выбора элементов из массива.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#В данном случае она выбирает 5 уникальных индексов из диапазона от 0 до длины массива X_val_questions_padded.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ],
      "source": [
        "#1. Генерация случайных индексов\n",
        "#Случайный выбор индексов позволяет протестировать модель на небольшом подмножестве данных.\n",
        "#Это полезно для быстрой проверки работы модели и визуализации результатов без необходимости обрабатывать весь валидационный набор.\n",
        "#Выбор случайных вопросов также помогает избежать предвзятости, связанной с последовательным выбором.\n",
        "xindices = np.random.choice(len(X_val_questions_padded), 5, replace=False)\n",
        "#np.random.choice: Эта функция используется для случайного выбора элементов из массива.\n",
        "#В данном случае она выбирает 5 уникальных индексов из диапазона от 0 до длины массива X_val_questions_padded.\n",
        "#len(X_val_questions_padded): Возвращает количество вопросов в валидационном наборе данных (паддированных вопросов).\n",
        "#replace=False: Указывает, что выбор должен быть без замены, то есть один и тот же индекс не может быть выбран дважды.\n",
        "\n",
        "\n",
        "#2. Извлечение тестовых данных\n",
        "#Извлечение тестовых данных по выбранным индексам позволяет подготовить входные данные для предсказания.\n",
        "#Вопросы, сцены и истинные метки должны соответствовать друг другу, чтобы можно было корректно оценить качество предсказаний модели.\n",
        "#Это также помогает организовать данные в удобном формате для последующей обработки.\n",
        "test_questions = X_val_questions_padded[indices]\n",
        "test_scenes = X_val_scenes_padded[indices]\n",
        "test_labels = y_val_encoded[indices]\n",
        "# test_questions: Извлекает 5 вопросов из массива X_val_questions_padded по случайным индексам, сгенерированным на предыдущем шаге.\n",
        "# test_scenes: Извлекает соответствующие сцены из массива X_val_scenes_padded, используя те же индексы.\n",
        "# test_labels: Извлекает истинные метки (ответы) из массива y_val_encoded, используя те же индексы.\n",
        "\n",
        "#3. Прогнозирование ответов модели\n",
        "#Вызов метода predict на модели позволяет получить предсказания на основе входных данных (вопросов и сцен).\n",
        "#Это ключевой этап, так как именно здесь модель применяет свои знания, полученные в процессе обучения, для генерации ответов на новые вопросы.\n",
        "predict = model.predict({'question_input': test_questions, 'scene_input': test_scenes})\n",
        "#model.predict(...): Вызывает метод предсказания модели, передавая ей тестовые вопросы и сцены в виде словаря.\n",
        "#Модель возвращает вероятности для каждого класса (ответа) на основе входных данных.\n",
        "\n",
        "#4. Получение предсказанных классов\n",
        "#Функция np.argmax используется для извлечения индексов классов с максимальной вероятностью из массива предсказаний.\n",
        "#Это необходимо для определения конкретного ответа, который модель считает наиболее вероятным для каждого вопроса.\n",
        "#Без этого шага мы бы не смогли интерпретировать результаты модели.\n",
        "predicted = np.argmax(predict, axis=1)\n",
        "#np.argmax(predict, axis=1): Эта функция находит индекс максимального значения вдоль указанной оси (в данном случае по строкам).\n",
        "#Это означает, что мы получаем предсказанный класс (ответ) для каждого вопроса, который соответствует максимальной вероятности\n",
        "\n",
        "#5. Печать результатов\n",
        "for i, idx in enumerate(indices):\n",
        "    question_text = val_questions['questions'][idx]['question'] # original question\n",
        "    true_answer = label_encoder.inverse_transform([test_labels[i]])[0]\n",
        "    pred_answer = label_encoder.inverse_transform([predicted[i]])[0]\n",
        "    print(f\"--------------------------------------------------------------------------\\nQuestion: {question_text}\\nTrue Answer: {true_answer}\\nPredicted Answer: {pred_answer}\\n--------------------------------------------------------------------------\\n\")\n",
        "#Цикл for i, idx in enumerate(indices): Проходит по всем индексам, которые были выбраны ранее.\n",
        "#question_text = val_questions['questions'][idx]['question']: Извлекает оригинальный текст вопроса из валидационного набора данных по текущему индексу.\n",
        "#true_answer = label_encoder.inverse_transform([test_labels[i]]): Преобразует истинную метку (числовой код) обратно в текстовый ответ с помощью label_encoder.\n",
        "#pred_answer = label_encoder.inverse_transform([predicted[i]]): Аналогично преобразует предсказанный класс обратно в текстовый ответ.\n",
        "#print(...): Форматирует и выводит информацию о каждом вопросе:\n",
        "#Разделитель (--------------------------------------------------------------------------)\n",
        "#Текст вопроса (Question: ...)\n",
        "#Истинный ответ (True Answer: ...)\n",
        "#Предсказанный ответ (Predicted Answer: ...)\n",
        "#Разделитель для визуального отделения результатов."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}